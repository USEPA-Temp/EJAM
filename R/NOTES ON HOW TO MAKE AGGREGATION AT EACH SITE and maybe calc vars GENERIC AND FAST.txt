if (1 ==0 ) {

see EJAM-package.R and doaggregate 

NOTE ON BUFFER STATS AS POPWTD MEANS VS OTHERWTD MEANS VS RECALCULATED FROM AGGREGATED COUNTS:
If the numerator and denominator of some %-style indicator are available as counts by bg, then one could recalculate per site once counts were summed per site... but that is not what EJSCREEN reports seem to do... they take pop weighted means of all raw score indicators (raw, meaning not expressed as percentiles) regardless of whether pop was the true denominator of that pct (it is not for some ejscreen pcts), which is probably OK, and we want to replicate EJSCREEN? But then it will not replicate some other GIS analyses that actually did it more correctly and calculated overall percents from the aggregated, overall counts! The recalculation method requires providing the formulas for the calculated variables to ensure correct denominators, etc. 

NOTE ON BUFFER STATS LIKE EJ INDEX:
It is not entirely clear that the only way to show an EJ index in a buffer is to find the pop wtd mean of bg-level EJ index values in a buffer, but that is probably simplest to explain and probably is how EJSCREEN does it. 

NOTE ON BUFFER STATS LIKE PERCENTILE, WHICH ARE NEVER CALCULATED AS WTD MEANS OF BG SCORES IN A BUFFER:
The raw score is found for a buffer and then that is looked up in a percentile lookup table to see how to express it as a percentile (US, Region, and State percentiles are 3 separate values).
      
      raw envt scores like pm2.5 concentration,
      
      raw EJ indexes are NOT needed if recalculated 
-------------

    but possibly want to keep flexibility to use other weights than pop 
  (such as for percent low income, pre1960 units, linguistic isolation of hhld, whose denominators are households, built units, age25up, those with known poverty ratio)
  or 
  instead of doing wtd means for those with correct denominators having to be specified,
  could just sum the count variables and specify the whole formula to apply once per site per correct denominator. 
################################################
# general notes on R and data.table package
################################################

BIG BOOK OF R
https://www.bigbookofr.com/index.html
some graphics to look at:
library(inspectdf) 
https://bbc.github.io/rcookbook/#how_does_the_bbplot_package_work 
https://www.desmog.com/2022/01/11/proximity-oil-gas-drilling-hypertension-pregnancy-willis/


DATA TABLE - UPDATE BY REFERENCE TO AVOID COPIES:

General note on data.table and making copies vs just updating by reference:
https://stackoverflow.com/questions/10225098/understanding-exactly-when-a-data-table-is-a-reference-to-vs-a-copy-of-another
#
Be careful about supposedly assigning a data.table as if you thought a copy were being made:
dtalias <- dt  
because they are both aliases for the same actual object in memory
so subsequently  altering dt also alters dtalias!
#
 Also, if you pass dt to a function then the function does not have to return(dt) ! 
 the function's side effect  will alter the original dt back in the calling environment!! 
 simply via any changes by ref to dt  inside the function passed dt  like  f(dt) 
#
Since [.data.table incurs overhead to check the existence and type of arguments (for example), set() provides direct (but less flexible) assignment by reference with low overhead, appropriate for use inside a for loop. See examples. := is more powerful and flexible than set() because := is intended to be combined with i and by in single queries on large datasets.


see   https://rstudio-education.github.io/hopr/modify.html 


COLLAPSE: 
Even faster than data.table in some scenarios, is new package called collapse
install.packages("collapse")
library(collapse)
help('collapse-documentation')
fmean()
??num_vars

################################################
}
